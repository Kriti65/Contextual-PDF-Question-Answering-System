{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "080dd76d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dc2d097d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import TextLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d799a896",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q cassio datasets langchain openai tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2a5df5d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores.cassandra import Cassandra\n",
    "from langchain.indexes.vectorstore import VectorStoreIndexWrapper\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from datasets import load_dataset\n",
    "import cassio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4940cda3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PyPDF2 import PdfReader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d6e953e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "AstradbApplicationToken = \"AstraCS:ewyGizIiRUSWIFGLnXkwKWHz:b31dda3c4c663c915a481f9e1b74515f912a5a8d6395a210a529583915464a94\"\n",
    "AstradbID = \"58b748f7-2b8f-4fe6-885b-28d5b5b5cddb\"\n",
    "OpenaiApiKey = \"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\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "716eaf65",
   "metadata": {},
   "outputs": [],
   "source": [
    "readpdf = PdfReader(\"Specturm.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c565d57a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing_extensions import Concatenate\n",
    "rawtext =\" \"\n",
    "for i, page in enumerate(readpdf.pages):\n",
    "    content = page.extract_text()\n",
    "    if content:\n",
    "        rawtext += content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84574c93",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b23b2e5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cassio.init(token =AstradbApplicationToken, database_id =AstradbID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b69f5b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI(openai_api_key = OpenaiApiKey, model=\"text-embedding-ada-002\")\n",
    "embedding = OpenAIEmbeddings(openai_api_key = OpenaiApiKey, model =\"text-embedding-ada-002\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "609e5e18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to Astra DB: {'status': {'collections': []}}\n"
     ]
    }
   ],
   "source": [
    "from astrapy.db import AstraDB\n",
    "\n",
    "# Initialization\n",
    "db = AstraDB(\n",
    "  token=\"AstraCS:ewyGizIiRUSWIFGLnXkwKWHz:b31dda3c4c663c915a481f9e1b74515f912a5a8d6395a210a529583915464a94\",\n",
    "  api_endpoint=\"https://58b748f7-2b8f-4fe6-885b-28d5b5b5cddb-us-east1.apps.astra.datastax.com\")\n",
    "\n",
    "print(f\"Connected to Astra DB: {db.get_collections()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "dda7e61a",
   "metadata": {},
   "outputs": [],
   "source": [
    "astra_vector_store = Cassandra(\n",
    "    embedding = embedding,\n",
    "    table_name = \"qa_demo\",\n",
    "    session = None,\n",
    "    keyspace = None,\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "13a77a7f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'CharacterTextSpiltter' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[104], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtext_splitter\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CharacterTextSplitter\n\u001b[1;32m----> 2\u001b[0m text_splitter \u001b[38;5;241m=\u001b[39m \u001b[43mCharacterTextSpiltter\u001b[49m(\n\u001b[0;32m      3\u001b[0m     seprator \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m      4\u001b[0m     chunk_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m800\u001b[39m,\n\u001b[0;32m      5\u001b[0m     chunk_overlap \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m200\u001b[39m,\n\u001b[0;32m      6\u001b[0m     length_function \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m\n\u001b[0;32m      7\u001b[0m )\n\u001b[0;32m      8\u001b[0m texts \u001b[38;5;241m=\u001b[39m text_splitter\u001b[38;5;241m.\u001b[39mspilt_text(rawtext)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'CharacterTextSpiltter' is not defined"
     ]
    }
   ],
   "source": [
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "text_splitter = CharacterTextSpiltter(\n",
    "    seprator = \"\\n\",\n",
    "    chunk_size = 800,\n",
    "    chunk_overlap = 200,\n",
    "    length_function = len\n",
    ")\n",
    "texts = text_splitter.spilt_text(rawtext)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "5187ba56",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import CharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "7b41b111",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = CharacterTextSplitter(\n",
    "    separator = \"\\n\",\n",
    "    chunk_size = 800,\n",
    "    chunk_overlap = 200,\n",
    "    length_function = len\n",
    ")\n",
    "texts = text_splitter.split_text(rawtext)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "513f5a6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inserted 50 headlines.\n"
     ]
    }
   ],
   "source": [
    "astra_vector_store.add_texts(texts[:50])\n",
    "print(\"Inserted %i headlines.\" %len(texts[:50]))\n",
    "astra_vector_index = VectorStoreIndexWrapper(vectorstore = astra_vector_store)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "32d95edb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Enter Your Question <or type 'quit' to exit>What are Alternative Deliver Channels are strategic for banks and other DFS providers?\n",
      "\n",
      "Question: \"What are Alternative Deliver Channels are strategic for banks and other DFS providers?\"\n",
      "Answer: \"-2 2a.h\n",
      "\n",
      "ch\n",
      "\n",
      ", 2a. 2a.\n",
      "\n",
      "2a.\n",
      "\n",
      " 1-2a\n",
      "\n",
      "2a\n",
      "\n",
      "h, 2a\n",
      "\n",
      "a, 2a, 2a, 2a, 2a,2a,2A, 2aand2b 1\n",
      "\n",
      "2a\n",
      "\n",
      "a.1 1-2a 2a2the2b2a\n",
      "\n",
      "and 2a\n",
      "\n",
      "1 2a2D.\n",
      "\n",
      "1a,2a,2a1,2a,2a1d 2a2B-1aD 1 1b,2a 1a,2a\n",
      "\n",
      "-2a 2a\n",
      "\n",
      "2a1,2a1 1a1 2a2a1and1\n",
      "\n",
      " 2CnD1a1a1 2a\n",
      "\n",
      ", 2Bb,1a1\n",
      "a\n",
      "\n",
      "2a 1C1a1a 1\n",
      "\n",
      " 1a2a1A 1a1aA.\n",
      "\n",
      "2a1a 2a2a2\n",
      "\n",
      "1a1a1S\n",
      "\n",
      "2a1A1\n",
      "\n",
      "2a,1 1a1\"\n",
      "\n",
      "FIRST DOCUMENT BY RELEVANCE\n",
      "  [0.8954] \"Dr. Anand Thakur, Hayatullah Jawhar  \n",
      "7.  Role and Impact of Alternate Banking Deliv...\"\n",
      "  [0.8848] \"dominating our daily lives.     \n",
      "As we step into this New Normal of a hyper-digital ...\"\n",
      "  [0.8844] \"to policymakers and the interconnected global econo my. Governments globally have re...\"\n",
      "  [0.8818] \"Mamatha Shree S., Dr. Baba Gnanakumar  \n",
      "39.  A Comparative Study of Financial Perfor...\"\n",
      "\n",
      "What Is Your Next Question? <or type 'quit' to exit>What % of insurance shoppers interact with at least one digital channel throughout their buyer journey\n",
      "\n",
      "Question: \"What % of insurance shoppers interact with at least one digital channel throughout their buyer journey\"\n",
      "Answer: \"e   1  1\n",
      "\n",
      " 1  1 1 1 1 1 1 1 1\n",
      "\n",
      "1 1 1 1 1 1 1 1\n",
      "\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "1 1 1 1 1 1 1 1 1 1 1 1   1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1By, 1 1 1 1 1 1 1 1 1\n",
      "\n",
      " 1 1 1 1The 1 1 1 1 1 1 1C 1 1 1 1 1, 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\"\n",
      "\n",
      "FIRST DOCUMENT BY RELEVANCE\n",
      "  [0.8854] \"15.  Segmentation of Markets Based on Customer Service . ..............................\"\n",
      "  [0.8836] \"dominating our daily lives.     \n",
      "As we step into this New Normal of a hyper-digital ...\"\n",
      "  [0.8774] \"Annreeta Thomas, Dr. Aloysius Edward J.  \n",
      "18.  A Study on Buying Behaviour of Home F...\"\n",
      "  [0.8746] \"Dr. PC Gita, Faculty, School of Management \n",
      "Kristu Jayanti College (Autonomous),  \n",
      "B...\"\n",
      "\n",
      "What Is Your Next Question? <or type 'quit' to exit>quit\n"
     ]
    }
   ],
   "source": [
    "firstQues = True\n",
    "while True:\n",
    "    if firstQues:\n",
    "        querytext = input(\"\\nEnter Your Question <or type 'quit' to exit>\")\n",
    "    else:\n",
    "        querytext = input(\"\\nWhat Is Your Next Question? <or type 'quit' to exit>\")\n",
    "    if querytext.lower()== \"quit\":\n",
    "        break\n",
    "    if querytext == \"\":\n",
    "        continue\n",
    "    firstQues= False\n",
    "    \n",
    "    print(\"\\nQuestion: \\\"%s\\\"\" % querytext)\n",
    "    answer = astra_vector_index.query(querytext, llm=llm).strip()\n",
    "    print(\"Answer: \\\"%s\\\"\\n\" %answer)\n",
    "    \n",
    "    print(\"FIRST DOCUMENT BY RELEVANCE\")\n",
    "    for doc, score in astra_vector_store.similarity_search_with_score(querytext, k=4):\n",
    "        print(\"  [%0.4f] \\\"%s...\\\"\" % (score, doc.page_content[:84]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "8cc9737a",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "expected ':' (1561849989.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[70], line 1\u001b[1;36m\u001b[0m\n\u001b[1;33m    try {\u001b[0m\n\u001b[1;37m        ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m expected ':'\n"
     ]
    }
   ],
   "source": [
    "try {\n",
    "        const result = await openai.createCompletion({\n",
    "            model: \"gpt-3.5-turbo-instruct\",\n",
    "            prompt: ` ${promptValue} ${prompt}`,\n",
    "            max_tokens: 2048,\n",
    "            temperature: 0,\n",
    "            top_p: 1,\n",
    "            n: 1,\n",
    "            stream: true,\n",
    "        }, { responseType: 'stream' });\n",
    "        \n",
    "        result.data.on('data', data => {\n",
    "            console.log(data);\n",
    "            const lines = data.toString().split('\\n').filter(line => line.trim() !== '');\n",
    "            for (const line of lines) {\n",
    "                const message = line.replace(/^data: /, '');\n",
    "                if (message === '[DONE]') {\n",
    "                    res.end();\n",
    "                    return; // Stream finished\n",
    "                }\n",
    "                try {\n",
    "                    const parsed = JSON.parse(message);\n",
    "                    console.log(parsed.choices[0].text);\n",
    "                    let responseData = parsed.choices[0].text;\n",
    "                    res.write(`data: ${responseData}\\n\\n`);\n",
    "                } catch(error) {\n",
    "                    console.error('Could not JSON parse stream message', message, error);\n",
    "                }\n",
    "            }\n",
    "        });\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "    } catch (error) {\n",
    "        if (error.response?.status) {\n",
    "            console.error(error.response.status, error.message);\n",
    "            error.response.data.on('data', data => {\n",
    "                const message = data.toString();\n",
    "                try {\n",
    "                    const parsed = JSON.parse(message);\n",
    "                    console.error('An error occurred during OpenAI request: ', parsed);\n",
    "                } catch(error) {\n",
    "                    console.error('An error occurred during OpenAI request: ', message);\n",
    "                }\n",
    "            });\n",
    "        } else {\n",
    "            console.error('An error occurred during OpenAI request', error);\n",
    "        }\n",
    "    }\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "a582e2cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import json\n",
    "import openai\n",
    "\n",
    "async def fetch_openai_completion(prompt_value, prompt):\n",
    "    try:\n",
    "        openai.api_key = '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'  # Replace with your OpenAI API key\n",
    "        stream = await openai.Completion.create(\n",
    "            model=\"text-davinci-003\",\n",
    "            prompt=f\"{prompt_value} {prompt}\",\n",
    "            max_tokens=2048,\n",
    "            temperature=0,\n",
    "            top_p=1,\n",
    "            n=1,\n",
    "            stream=True\n",
    "        )\n",
    "\n",
    "        async for data in stream:\n",
    "            print(data)\n",
    "            lines = data.split('\\n')\n",
    "            lines = [line.strip() for line in lines if line.strip() != '']\n",
    "            for line in lines:\n",
    "                message = line.replace('data: ', '')\n",
    "                if message == '[DONE]':\n",
    "                    return\n",
    "                try:\n",
    "                    parsed = json.loads(message)\n",
    "                    print(parsed['choices'][0]['text'])\n",
    "                    response_data = parsed['choices'][0]['text']\n",
    "                    # Here you would send the response data to the client\n",
    "                    # For example, if using a web framework like Flask or Django:\n",
    "                    # yield f\"data: {response_data}\\n\\n\"\n",
    "                except json.JSONDecodeError as error:\n",
    "                    print('Could not JSON parse stream message', message, error)\n",
    "\n",
    "    except openai.error.OpenAIError as error:\n",
    "        if error.response and error.response.status_code:\n",
    "            print(error.response.status_code, error.message)\n",
    "            async for data in error.response.iter_content():\n",
    "                message = data.decode()\n",
    "                try:\n",
    "                    parsed = json.loads(message)\n",
    "                    print('An error occurred during OpenAI request: ', parsed)\n",
    "                except json.JSONDecodeError as error:\n",
    "                    print('An error occurred during OpenAI request: ', message)\n",
    "        else:\n",
    "            print('An error occurred during OpenAI request', error)\n",
    "\n",
    "# To use the function, you would call it with asyncio.run if not already inside an async function\n",
    "# asyncio.run(fetch_openai_completion(prompt_value, prompt))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "eb84a041",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.api_key = \"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\"\n",
    "model_engine = \"text-davinci- 003\"\n",
    "def generate_response(question):\n",
    "    \n",
    "    response = openai.Completion.create(\n",
    "    engine=model_engine,\n",
    "    prompt=question,\n",
    "    max_tokens=1024,        \n",
    "    n=1,\n",
    "    stop=None,\n",
    "    temperature=0.7,\n",
    "        \n",
    "    \n",
    ")\n",
    "    return response.choices[0].text.strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "7cc42791",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tkinter as tk\n",
    "root = tk.Tk()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "68ae4f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_window = tk.Frame(root)\n",
    "input_label = tk.Label(input_window, text=\"Enter your question:\")\n",
    "input_label.pack(side=tk.LEFT)\n",
    "input_entry = tk.Entry(input_window)\n",
    "input_entry.pack(side=tk.LEFT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "5eb6a8f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "response_window = tk.Frame(root)\n",
    "response_label = tk.Label(response_window, text=\"Response:\")\n",
    "response_label.pack(side=tk.LEFT)\n",
    "response_text = tk.Text(response_window)\n",
    "response_text.pack(side=tk.LEFT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "34e2ba6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_response():\n",
    "    \n",
    "    question = input_entry.get()\n",
    "    response = generate_response(question)\n",
    "    response_text.delete(\"1.0\", tk.END)\n",
    "    response_text.insert(tk.END, response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "f8495da6",
   "metadata": {},
   "outputs": [],
   "source": [
    "button = tk.Button(root, text=\"Get Response\", command=get_response)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "1d82a828",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_window.pack()\n",
    "response_window.pack()\n",
    "button.pack()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "d1eb010b",
   "metadata": {},
   "outputs": [],
   "source": [
    "root.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "484b46d9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
